import asyncio
import re
import time
from typing import List, Optional, Dict, Any
from urllib.parse import urlparse, parse_qs

from playwright.async_api import async_playwright, Page, Browser
from loguru import logger

from app.models.schemas import ReviewData


class DanawaCrawler:
    """ëª¨ë°”ì¼ ë‹¤ë‚˜ì™€ í¬ë¡¤ëŸ¬ - Playwright ì „ìš©"""
    
    def __init__(self):
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
        self.playwright = None
    
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=True,
            args=[
                '--disable-dev-shm-usage', 
                '--no-sandbox', 
                '--disable-gpu',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor',
                '--user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1'
            ]
        )
        
        context = await self.browser.new_context(
            viewport={'width': 375, 'height': 667},  # ëª¨ë°”ì¼ ë·°í¬íŠ¸
            user_agent='Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1',
            extra_http_headers={
                'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
            }
        )
        
        self.page = await context.new_page()
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        self.page.set_default_timeout(60000)  # 60ì´ˆ
        
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        try:
            if self.page:
                await self.page.close()
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
        except Exception as e:
            logger.error(f"ë¸Œë¼ìš°ì € ì¢…ë£Œ ì˜¤ë¥˜: {e}")
    
    def extract_product_code(self, url: str) -> Optional[str]:
        """ë‹¤ë‚˜ì™€ URLì—ì„œ ìƒí’ˆ ì½”ë“œë¥¼ ì¶”ì¶œ"""
        try:
            parsed = urlparse(str(url))
            if 'danawa.com' not in parsed.netloc:
                return None
            
            # URLì—ì„œ code íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ëª¨ë°”ì¼)
            query_params = parse_qs(parsed.query)
            if 'code' in query_params:
                return query_params['code'][0]
            
            # URLì—ì„œ pcode íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ë°ìŠ¤í¬í†±)
            if 'pcode' in query_params:
                return query_params['pcode'][0]
            
            # URL ê²½ë¡œì—ì„œ ìƒí’ˆ ì½”ë“œ ì¶”ì¶œ ì‹œë„
            path_match = re.search(r'/(\d+)/?$', parsed.path)
            if path_match:
                return path_match.group(1)
                
            return None
        except Exception:
            return None
    
    async def crawl_reviews(self, product_url: str, max_reviews: int = 100) -> List[ReviewData]:
        """ëª¨ë°”ì¼ ë‹¤ë‚˜ì™€ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§"""
        reviews = []

        try:
            logger.info(f"ğŸš€ ëª¨ë°”ì¼ ìƒí’ˆ í˜ì´ì§€ ì ‘ê·¼: {product_url}")
            
            # ëª¨ë°”ì¼ ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™
            await self.page.goto(str(product_url), wait_until='domcontentloaded', timeout=60000)
            await asyncio.sleep(3)
            logger.info("âœ… ëª¨ë°”ì¼ ìƒí’ˆ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
            
            # í˜ì´ì§€ ìŠ¤í¬ë¡¤í•˜ì—¬ ì½˜í…ì¸  ë¡œë“œ
            await self._scroll_to_load_content()
            
            # ë¦¬ë·° ì„¹ì…˜ìœ¼ë¡œ ì´ë™
            review_found = await self._navigate_to_mobile_reviews()
            
            if review_found:
                # ì‚¬ìš©ìê°€ ì„¤ì •í•œ ê°œìˆ˜ë§Œí¼ ë¦¬ë·° ë¡œë“œë¥¼ ìœ„í•´ ë”ë³´ê¸° ë²„íŠ¼ ë°˜ë³µ í´ë¦­
                await self._click_more_reviews_if_needed(max_reviews)
                
                # ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ
                reviews = await self._extract_mobile_reviews(max_reviews)
            
            logger.info(f"ğŸ‰ ì´ {len(reviews)}ê°œì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")

        except Exception as e:
            logger.error(f"âŒ ëª¨ë°”ì¼ ë¦¬ë·° í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        return reviews
    
    async def extract_product_info(self, product_url: str) -> Dict[str, Optional[str]]:
        """ë‹¤ë‚˜ì™€ ìƒí’ˆ í˜ì´ì§€ì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
        product_info = {
            'product_name': None,
            'image_url': None,
            'price': None,
            'brand': None
        }
        
        try:
            logger.info(f"ğŸ” ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì‹œì‘: {product_url}")
            
            # self.pageê°€ Noneì¸ì§€ í™•ì¸
            if not self.page:
                logger.error("âŒ ë¸Œë¼ìš°ì € í˜ì´ì§€ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return product_info
            
            # ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™ (ì•„ì§ ì•ˆí–ˆë‹¤ë©´)
            current_url = self.page.url
            if current_url != product_url:
                await self.page.goto(str(product_url), wait_until='domcontentloaded', timeout=60000)
                await asyncio.sleep(3)
            
            # í˜ì´ì§€ ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ
            await self._scroll_to_load_content()
            
            # ìƒí’ˆëª… ì¶”ì¶œ - ì‚¬ìš©ì ì œê³µ ì •í™•í•œ ì„ íƒì
            product_name_selectors = [
                "#productBlog-productName",  # ì‚¬ìš©ì ì œê³µ ì •í™•í•œ ì„ íƒì
                ".product_title",  # ë°±ì—… ì„ íƒì
                ".product-title",
                ".prod_name",
                ".item_name",
                ".product_name",
                "h1.title",
                "h1.product-title",
                ".title_area h1",
                ".prod_info h1",
                "h1",  # ë§ˆì§€ë§‰ ëŒ€ì•ˆ
                ".item_title"
            ]
            
            for selector in product_name_selectors:
                try:
                    logger.debug(f"ğŸ” ìƒí’ˆëª… ì„ íƒì ì‹œë„: {selector}")
                    element = await self.page.query_selector(selector)
                    if element:
                        product_name = await element.inner_text()
                        logger.debug(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {product_name}")
                        if product_name and len(product_name.strip()) > 0:
                            product_info['product_name'] = product_name.strip()
                            logger.info(f"âœ… ìƒí’ˆëª… ì¶”ì¶œ ì„±ê³µ: {product_name[:50]}...")
                            break
                    else:
                        logger.debug(f"âŒ ì„ íƒì {selector}ë¡œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                except Exception as e:
                    logger.debug(f"âŒ ì„ íƒì {selector} ì˜¤ë¥˜: {e}")
                    continue
            
            # ìƒí’ˆ ì´ë¯¸ì§€ ì¶”ì¶œ - ì‚¬ìš©ì ì œê³µ ì •í™•í•œ ì„ íƒì
            image_selectors = [
                "#productBlog-image-item-0 > span > img",  # ì‚¬ìš©ì ì œê³µ ì •í™•í•œ ì„ íƒì
                "#productBlog-image-item-1 > span > img",  # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€
                "#productBlog-image-item-2 > span > img",  # ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€
                ".thumb_area img",  # ë°±ì—… ì„ íƒì
                ".product_img img",
                ".item_img img", 
                ".prod_img img",
                ".product_image img",
                ".main_image img",
                ".swiper-slide img",  # ë‹¤ë‚˜ì™€ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ìŠ¬ë¼ì´ë”
                ".thumb_list img",
                ".gallery img",
                "img[src*='danawa']",  # ë‹¤ë‚˜ì™€ ì´ë¯¸ì§€ ì„œë²„
                "img[alt*='ìƒí’ˆ']",
                "img[alt*='ì œí’ˆ']",
                "img[data-src*='danawa']",  # ì§€ì—° ë¡œë”© ì´ë¯¸ì§€
                "img"  # ë§ˆì§€ë§‰ ëŒ€ì•ˆ
            ]
            
            for selector in image_selectors:
                try:
                    logger.debug(f"ğŸ” ì´ë¯¸ì§€ ì„ íƒì ì‹œë„: {selector}")
                    element = await self.page.query_selector(selector)
                    if element:
                        src = await element.get_attribute('src')
                        data_src = await element.get_attribute('data-src')
                        alt = await element.get_attribute('alt')
                        logger.debug(f"ğŸ“· src: {src}, data-src: {data_src}")
                        
                        # src ë˜ëŠ” data-src ì¤‘ ìœ íš¨í•œ ê²ƒ ì‚¬ìš©
                        image_url = src or data_src
                        
                        # ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸
                        if image_url and ('jpg' in image_url.lower() or 'jpeg' in image_url.lower() or 'png' in image_url.lower() or 'webp' in image_url.lower()):
                            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                            if image_url.startswith('/'):
                                image_url = f"https://img.danawa.com{image_url}"
                            elif image_url.startswith('//'):
                                image_url = f"https:{image_url}"
                            
                            product_info['image_url'] = image_url
                            logger.info(f"âœ… ìƒí’ˆ ì´ë¯¸ì§€ ì¶”ì¶œ ì„±ê³µ: {image_url}")
                            break
                    else:
                        logger.debug(f"âŒ ì„ íƒì {selector}ë¡œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                except Exception as e:
                    logger.debug(f"âŒ ì„ íƒì {selector} ì˜¤ë¥˜: {e}")
                    continue
            
            # ê°€ê²© ì •ë³´ ì¶”ì¶œ (ì„ íƒì‚¬í•­)
            price_selectors = [
                ".price_real",
                ".price_current",
                ".price",
                "[class*='price']",
                ".price_info .price"
            ]
            
            for selector in price_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        price_text = await element.inner_text()
                        if price_text and 'ì›' in price_text:
                            product_info['price'] = price_text.strip()
                            logger.info(f"âœ… ê°€ê²© ì •ë³´ ì¶”ì¶œ: {price_text}")
                            break
                except:
                    continue
            
            # ë¸Œëœë“œ ì •ë³´ ì¶”ì¶œ (ì„ íƒì‚¬í•­)
            brand_selectors = [
                ".brand_name",
                ".brand",
                "[class*='brand']",
                ".manufacturer"
            ]
            
            for selector in brand_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        brand_text = await element.inner_text()
                        if brand_text and len(brand_text.strip()) > 0:
                            product_info['brand'] = brand_text.strip()
                            logger.info(f"âœ… ë¸Œëœë“œ ì •ë³´ ì¶”ì¶œ: {brand_text}")
                            break
                except:
                    continue
            
        except Exception as e:
            logger.error(f"âŒ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return product_info
    
    async def _scroll_to_load_content(self):
        """ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ì½˜í…ì¸  ë¡œë“œ"""
        try:
            logger.info("ğŸ“œ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
            for i in range(3):
                await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await asyncio.sleep(2)
            logger.info("âœ… ìŠ¤í¬ë¡¤ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}")
    
    async def _navigate_to_mobile_reviews(self) -> bool:
        """ëª¨ë°”ì¼ ì‚¬ì´íŠ¸ì—ì„œ ë¦¬ë·° ì„¹ì…˜ìœ¼ë¡œ ì´ë™"""
        logger.info("ğŸ” ëª¨ë°”ì¼ ë¦¬ë·° ì„¹ì…˜ ì°¾ëŠ” ì¤‘...")
        
        # ì‚¬ìš©ìê°€ ì œê³µí•œ ì •í™•í•œ ë¦¬ë·° ë²„íŠ¼ ì…€ë ‰í„°
        review_button_selector = "#productBlog-starsButton > div.text__review > span.text__number"
        
        try:
            # ë¦¬ë·° ë²„íŠ¼ í´ë¦­
            review_button = await self.page.query_selector(review_button_selector)
            if review_button:
                logger.info(f"âœ… ë¦¬ë·° ë²„íŠ¼ ë°œê²¬!")
                await review_button.click()
                await asyncio.sleep(3)
                logger.info("âœ… ë¦¬ë·° ì„¹ì…˜ìœ¼ë¡œ ì´ë™ ì™„ë£Œ")
                return True
            else:
                logger.error("âŒ ë¦¬ë·° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
        except Exception as e:
            logger.error(f"âŒ ë¦¬ë·° íƒ­ í´ë¦­ ì‹¤íŒ¨: {e}")
            return False
    
    async def _click_more_reviews_if_needed(self, target_reviews: int):
        """ì‚¬ìš©ìê°€ ì„¤ì •í•œ ê°œìˆ˜ë§Œí¼ ë¦¬ë·°ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•´ ë”ë³´ê¸° ë²„íŠ¼ì„ ë°˜ë³µ í´ë¦­"""
        logger.info(f"ğŸ” ëª©í‘œ {target_reviews}ê°œ ë¦¬ë·° ë¡œë“œë¥¼ ìœ„í•œ ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì‹œì‘...")
        
        # ì‚¬ìš©ìê°€ ì œê³µí•œ ì •í™•í•œ í¼ì³ë³´ê¸° ì…€ë ‰í„°
        more_button_selector = "#productBlog-opinion-mall-button-viewMore > span"
        
        # ê¸°ë³¸ì ìœ¼ë¡œ 30ê°œ ì •ë„ ë³´ì´ë¯€ë¡œ, ì¶”ê°€ë¡œ í•„ìš”í•œ ë§Œí¼ ë”ë³´ê¸° í´ë¦­
        # í•œ ë²ˆ í´ë¦­í•  ë•Œë§ˆë‹¤ ì•½ 30-50ê°œì”© ì¶”ê°€ ë¡œë“œë¨
        estimated_clicks = max(1, (target_reviews - 30) // 30)
        max_clicks = min(estimated_clicks + 2, 20)  # ìµœëŒ€ 20ë²ˆê¹Œì§€ë§Œ í´ë¦­ (ì•ˆì „ì¥ì¹˜)
        
        logger.info(f"ğŸ“Š ì˜ˆìƒ ë”ë³´ê¸° í´ë¦­ íšŸìˆ˜: {estimated_clicks}, ìµœëŒ€ í´ë¦­ íšŸìˆ˜: {max_clicks}")
        
        click_count = 0
        for i in range(max_clicks):
            try:
                more_button = await self.page.query_selector(more_button_selector)
                if more_button:
                    # ë²„íŠ¼ì´ ë³´ì´ëŠ”ì§€ í™•ì¸
                    is_visible = await more_button.is_visible()
                    if is_visible:
                        logger.info(f"âœ… ë”ë³´ê¸° ë²„íŠ¼ {i+1}ë²ˆì§¸ í´ë¦­!")
                        await more_button.click()
                        click_count += 1
                        await asyncio.sleep(3)  # ë¡œë”© ëŒ€ê¸°
                        
                        # í˜„ì¬ ë¡œë“œëœ ë¦¬ë·° ê°œìˆ˜ í™•ì¸
                        current_reviews = await self.page.query_selector_all('[id*="productBlog-opinion-mall-list-listItem-"]')
                        current_count = len(current_reviews)
                        logger.info(f"ğŸ“ í˜„ì¬ ë¡œë“œëœ ë¦¬ë·°: {current_count}ê°œ")
                        
                        # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¤‘ë‹¨
                        if current_count >= target_reviews:
                            logger.info(f"ğŸ¯ ëª©í‘œ ê°œìˆ˜({target_reviews})ì— ë„ë‹¬! ë”ë³´ê¸° í´ë¦­ ì¤‘ë‹¨")
                            break
                    else:
                        logger.info("ğŸ”š ë”ë³´ê¸° ë²„íŠ¼ì´ ë³´ì´ì§€ ì•ŠìŒ - ëª¨ë“  ë¦¬ë·° ë¡œë“œ ì™„ë£Œ")
                        break
                else:
                    logger.info("ğŸ”š ë”ë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ëª¨ë“  ë¦¬ë·° ë¡œë“œ ì™„ë£Œ")
                    break
                    
            except Exception as e:
                logger.error(f"âŒ ë”ë³´ê¸° ë²„íŠ¼ {i+1}ë²ˆì§¸ í´ë¦­ ì‹¤íŒ¨: {e}")
                break
        
        logger.info(f"ğŸ‰ ì´ {click_count}ë²ˆì˜ ë”ë³´ê¸° í´ë¦­ ì™„ë£Œ")
    
    async def _extract_mobile_reviews(self, max_reviews: int) -> List[ReviewData]:
        """ëª¨ë°”ì¼ í˜ì´ì§€ì—ì„œ ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ"""
        reviews = []
        
        logger.info("ğŸ” ëª¨ë°”ì¼ ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        try:
            # ë¦¬ë·° ì»¨í…Œì´ë„ˆë“¤ ì°¾ê¸° (ë™ì  ID íŒ¨í„´)
            # ì‚¬ìš©ì ì˜ˆì‹œ: #productBlog-opinion-mall-list-listItem-9123372001990022352 > div
            review_containers = await self.page.query_selector_all('[id*="productBlog-opinion-mall-list-listItem-"] > div')
            logger.info(f"ğŸ“ ë°œê²¬ëœ ë¦¬ë·° ì»¨í…Œì´ë„ˆ: {len(review_containers)}ê°œ")
            
            if not review_containers:
                logger.error("âŒ ë¦¬ë·° ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return reviews
            
            review_count = 0
            for i, container in enumerate(review_containers):
                if review_count >= max_reviews:
                    break
                
                try:
                    # ì»¨í…Œì´ë„ˆì˜ IDì—ì„œ ìˆ«ì ì¶”ì¶œ
                    container_id = await container.get_attribute('id')
                    if not container_id:
                        # ë¶€ëª¨ ìš”ì†Œì˜ IDì—ì„œ ì¶”ì¶œ ì‹œë„
                        parent = await container.query_selector('xpath=..')
                        if parent:
                            container_id = await parent.get_attribute('id')
                    
                    if container_id and 'productBlog-opinion-mall-list-listItem-' in container_id:
                        # IDì—ì„œ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
                        review_id = container_id.replace('productBlog-opinion-mall-list-listItem-', '')
                        
                        # í•´ë‹¹ ë¦¬ë·°ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°
                        # ì‚¬ìš©ì ì˜ˆì‹œ: #productBlog-opinion-mall-list-content-9123372001990022352
                        text_selector = f"#productBlog-opinion-mall-list-content-{review_id}"
                        text_element = await self.page.query_selector(text_selector)
                        
                        # ë³„ì  ì°¾ê¸° 
                        # ì‚¬ìš©ì ì˜ˆì‹œ: #productBlog-opinion-mall-list-listItem-9123372001865032107 > div > div > div:nth-child(1) > div > span > span
                        rating_selector = f"#productBlog-opinion-mall-list-listItem-{review_id} > div > div > div:nth-child(1) > div > span > span"
                        rating_element = await self.page.query_selector(rating_selector)
                        
                        # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        review_text = ""
                        if text_element:
                            review_text = await text_element.inner_text()
                            review_text = review_text.strip()
                        
                        # ë³„ì  ì¶”ì¶œ
                        rating = 0
                        if rating_element:
                            rating_text = await rating_element.inner_text()
                            # ë³„ì  í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "5ì " -> 5)
                            rating_match = re.search(r'(\d+)', rating_text)
                            if rating_match:
                                rating = int(rating_match.group(1))
                        
                        if review_text and len(review_text) > 10:  # ì˜ë¯¸ìˆëŠ” ê¸¸ì´ì˜ ë¦¬ë·°ë§Œ
                            review_data = ReviewData(
                                review_id=review_id,
                                content=review_text,
                                rating=rating if rating > 0 else None,
                                author="ìµëª…",  # ëª¨ë°”ì¼ì—ì„œëŠ” ì‘ì„±ì ì •ë³´ ì œí•œì 
                                date=None       # ë‚ ì§œ ì •ë³´ ì¶”ì¶œì´ í•„ìš”í•˜ë©´ ë³„ë„ ì…€ë ‰í„° í•„ìš”
                            )
                            reviews.append(review_data)
                            review_count += 1
                            logger.info(f"ğŸ“ ë¦¬ë·° {review_count}: {review_text[:50]}..." + (f" (â˜…{rating})" if rating > 0 else ""))
                    
                except Exception as e:
                    logger.error(f"âŒ ë¦¬ë·° {i+1} ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                    continue
            
            logger.info(f"ğŸ‰ ì´ {len(reviews)}ê°œì˜ ëª¨ë°”ì¼ ë¦¬ë·° ì¶”ì¶œ ì™„ë£Œ!")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë°”ì¼ ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return reviews


async def crawl_danawa_reviews(product_url: str, max_reviews: int = 100) -> Dict[str, Any]:
    """ë‹¤ë‚˜ì™€ ë¦¬ë·° í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜"""
    async with DanawaCrawler() as crawler:
        try:
            # 1. ìƒí’ˆ ì •ë³´ ë¨¼ì € ì¶”ì¶œ
            logger.info("ğŸ” ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘...")
            product_info = await crawler.extract_product_info(product_url)
            
            # 2. ë¦¬ë·° í¬ë¡¤ë§
            logger.info("ğŸ“ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘...")
            reviews = await crawler.crawl_reviews(product_url, max_reviews)
            
            product_code = crawler.extract_product_code(product_url)
            
            # ì¶”ì¶œëœ ìƒí’ˆ ì •ë³´ ì‚¬ìš©
            product_name = product_info.get('product_name')
            if not product_name:
                product_name = f"ë‹¤ë‚˜ì™€ ìƒí’ˆ ({product_code})" if product_code else "ë‹¤ë‚˜ì™€ ìƒí’ˆ"
            
            # CrawlResponse ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë°˜í™˜ (ìƒí’ˆ ì •ë³´ í¬í•¨)
            return {
                "success": True,
                "product_id": product_code or "unknown",
                "product_name": product_name,
                "product_image": product_info.get('image_url'),  # ì´ë¯¸ì§€ URL ì¶”ê°€
                "product_price": product_info.get('price'),      # ê°€ê²© ì •ë³´ ì¶”ê°€
                "product_brand": product_info.get('brand'),      # ë¸Œëœë“œ ì •ë³´ ì¶”ê°€
                "total_reviews": len(reviews),
                "reviews": reviews,  # ReviewData ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
                "error_message": None
            }
            
        except Exception as e:
            logger.error(f"í¬ë¡¤ë§ ì „ì²´ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "product_id": "error", 
                "product_name": "Error",
                "product_image": None,
                "product_price": None,
                "product_brand": None,
                "total_reviews": 0,
                "reviews": [],
                "error_message": str(e)
            } 