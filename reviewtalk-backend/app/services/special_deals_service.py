"""
íŠ¹ê°€ ìƒí’ˆ ì„œë¹„ìŠ¤ - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
"""
import asyncio
from typing import List, Dict, Any
from datetime import datetime

from loguru import logger

from app.models.schemas import (
    SpecialProduct, 
    SpecialProductsResponse, 
    CrawlSpecialProductsRequest,
    CrawlSpecialProductsResponse
)
from app.infrastructure.special_product_repository import special_product_repository
from app.infrastructure.crawler.special_deals_crawler import crawl_special_deals
from app.infrastructure.crawler.danawa_crawler import crawl_danawa_reviews
from app.infrastructure.ai.vector_store import get_vector_store
from app.infrastructure.conversation_repository import conversation_repository


class SpecialDealsService:
    """íŠ¹ê°€ ìƒí’ˆ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.repository = special_product_repository
    
    async def crawl_and_save_special_deals(
        self, 
        request: CrawlSpecialProductsRequest
    ) -> CrawlSpecialProductsResponse:
        """íŠ¹ê°€ ìƒí’ˆ í¬ë¡¤ë§ ë° ì €ì¥"""
        logger.info(f"ğŸš€ íŠ¹ê°€ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘ - ìµœëŒ€ {request.max_products}ê°œ")
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            self.repository.init_db()
            
            # 1. íŠ¹ê°€ ìƒí’ˆ ëª©ë¡ í¬ë¡¤ë§
            logger.info("ğŸ“¦ íŠ¹ê°€ ìƒí’ˆ ëª©ë¡ í¬ë¡¤ë§ ì¤‘...")
            special_products = await crawl_special_deals(request.max_products)
            
            if not special_products:
                return CrawlSpecialProductsResponse(
                    success=False,
                    total_products=0,
                    products_with_reviews=0,
                    total_reviews=0,
                    error_message="íŠ¹ê°€ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # 2. íŠ¹ê°€ ìƒí’ˆ ì €ì¥
            saved_count = self.repository.save_special_products(special_products)
            logger.info(f"âœ… {saved_count}ê°œì˜ íŠ¹ê°€ ìƒí’ˆ ì €ì¥ ì™„ë£Œ")
            
            # 3. ê° ìƒí’ˆë³„ ë¦¬ë·° í¬ë¡¤ë§ (ì˜µì…˜)
            products_with_reviews = 0
            total_reviews = 0
            
            if request.crawl_reviews:
                logger.info("ğŸ“ ê° ìƒí’ˆë³„ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘...")
                
                for i, product in enumerate(special_products):
                    try:
                        logger.info(f"ğŸ“– ìƒí’ˆ {i+1}/{len(special_products)}: {product.product_name}")
                        
                        # ë¦¬ë·° í¬ë¡¤ë§
                        review_result = await crawl_danawa_reviews(
                            product.product_url, 
                            request.max_reviews_per_product
                        )
                        
                        if review_result.get("success") and review_result.get("reviews"):
                            reviews = review_result["reviews"]
                            review_count = len(reviews)
                            
                            # ë²¡í„° ì €ì¥ì†Œì— ë¦¬ë·° ì €ì¥
                            await self._save_reviews_to_vector_store(
                                product.product_id,
                                product.product_name,
                                reviews
                            )
                            
                            # í¬ë¡¤ë§ ìƒíƒœ ì—…ë°ì´íŠ¸
                            self.repository.update_crawl_status(
                                product.product_id, 
                                True, 
                                review_count
                            )
                            
                            products_with_reviews += 1
                            total_reviews += review_count
                            
                            logger.info(f"âœ… {product.product_name}: {review_count}ê°œ ë¦¬ë·° ì €ì¥")
                        else:
                            logger.warning(f"âš ï¸ {product.product_name}: ë¦¬ë·° í¬ë¡¤ë§ ì‹¤íŒ¨")
                        
                        # ê° ìƒí’ˆ ì²˜ë¦¬ í›„ ì ì‹œ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                        await asyncio.sleep(2)
                        
                    except Exception as e:
                        logger.error(f"âŒ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ ì˜¤ë¥˜ ({product.product_name}): {e}")
                        continue
            
            return CrawlSpecialProductsResponse(
                success=True,
                total_products=saved_count,
                products_with_reviews=products_with_reviews,
                total_reviews=total_reviews
            )
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ê°€ ìƒí’ˆ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
            return CrawlSpecialProductsResponse(
                success=False,
                total_products=0,
                products_with_reviews=0,
                total_reviews=0,
                error_message=str(e)
            )
    
    async def _save_reviews_to_vector_store(
        self, 
        product_id: str, 
        product_name: str, 
        reviews: List[Dict[str, Any]]
    ):
        """ë¦¬ë·°ë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì €ì¥"""
        try:
            documents = []
            metadatas = []
            ids = []
            
            for review in reviews:
                if hasattr(review, 'content') and review.content:
                    documents.append(review.content)
                    metadatas.append({
                        "product_id": product_id,
                        "product_name": product_name,
                        "rating": getattr(review, 'rating', None),
                        "author": getattr(review, 'author', None),
                        "date": getattr(review, 'date', None),
                        "review_id": getattr(review, 'review_id', None)
                    })
                    ids.append(f"{product_id}_{getattr(review, 'review_id', len(ids))}")
            
            if documents:
                vector_store = get_vector_store()
                product_info = {"product_name": product_name}
                vector_store.add_reviews(reviews, product_id, product_info)
                logger.info(f"âœ… {len(documents)}ê°œ ë¦¬ë·°ë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì €ì¥")
            
        except Exception as e:
            logger.error(f"âŒ ë²¡í„° ì €ì¥ì†Œ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def get_special_products(self, limit: int = 50, offset: int = 0) -> SpecialProductsResponse:
        """íŠ¹ê°€ ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
        try:
            products = self.repository.get_special_products(limit, offset)
            total_count = self.repository.get_total_count()
            
            return SpecialProductsResponse(
                success=True,
                total_count=total_count,
                products=products
            )
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ê°€ ìƒí’ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return SpecialProductsResponse(
                success=False,
                total_count=0,
                products=[],
                error_message=str(e)
            )
    
    def get_special_product_by_id(self, product_id: str) -> SpecialProduct:
        """íŠ¹ì • íŠ¹ê°€ ìƒí’ˆ ì¡°íšŒ"""
        try:
            return self.repository.get_special_product_by_id(product_id)
        except Exception as e:
            logger.error(f"âŒ íŠ¹ê°€ ìƒí’ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    async def process_uncrawled_products(self, batch_size: int = 5) -> Dict[str, Any]:
        """ì•„ì§ ë¦¬ë·°ê°€ í¬ë¡¤ë§ë˜ì§€ ì•Šì€ ìƒí’ˆë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
        logger.info(f"ğŸ”„ ë¯¸í¬ë¡¤ë§ ìƒí’ˆ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
        
        try:
            # ë¯¸í¬ë¡¤ë§ ìƒí’ˆ ì¡°íšŒ
            uncrawled_products = self.repository.get_uncrawled_products(batch_size)
            
            if not uncrawled_products:
                return {
                    "success": True,
                    "processed_count": 0,
                    "message": "ì²˜ë¦¬í•  ë¯¸í¬ë¡¤ë§ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤."
                }
            
            processed_count = 0
            total_reviews = 0
            
            for product in uncrawled_products:
                try:
                    logger.info(f"ğŸ“ ë¦¬ë·° í¬ë¡¤ë§: {product.product_name}")
                    
                    # ë¦¬ë·° í¬ë¡¤ë§
                    review_result = await crawl_danawa_reviews(product.product_url, 100)
                    
                    if review_result.get("success") and review_result.get("reviews"):
                        reviews = review_result["reviews"]
                        review_count = len(reviews)
                        
                        # ë²¡í„° ì €ì¥ì†Œì— ì €ì¥
                        await self._save_reviews_to_vector_store(
                            product.product_id,
                            product.product_name,
                            reviews
                        )
                        
                        # í¬ë¡¤ë§ ìƒíƒœ ì—…ë°ì´íŠ¸
                        self.repository.update_crawl_status(
                            product.product_id, 
                            True, 
                            review_count
                        )
                        
                        processed_count += 1
                        total_reviews += review_count
                        
                        logger.info(f"âœ… {product.product_name}: {review_count}ê°œ ë¦¬ë·° ì²˜ë¦¬ ì™„ë£Œ")
                    else:
                        # ì‹¤íŒ¨í•´ë„ ìƒíƒœëŠ” ì—…ë°ì´íŠ¸ (ì¬ì‹œë„ ë°©ì§€)
                        self.repository.update_crawl_status(product.product_id, True, 0)
                        logger.warning(f"âš ï¸ {product.product_name}: ë¦¬ë·° í¬ë¡¤ë§ ì‹¤íŒ¨")
                    
                    # ê° ìƒí’ˆ ì²˜ë¦¬ í›„ ëŒ€ê¸°
                    await asyncio.sleep(3)
                    
                except Exception as e:
                    logger.error(f"âŒ ìƒí’ˆ ì²˜ë¦¬ ì˜¤ë¥˜ ({product.product_name}): {e}")
                    # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.repository.update_crawl_status(product.product_id, True, 0)
                    continue
            
            return {
                "success": True,
                "processed_count": processed_count,
                "total_reviews": total_reviews,
                "message": f"{processed_count}ê°œ ìƒí’ˆì˜ ë¦¬ë·°ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¯¸í¬ë¡¤ë§ ìƒí’ˆ ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "processed_count": 0,
                "total_reviews": 0,
                "error_message": str(e)
            }
    
    def cleanup_old_products(self, days: int = 7) -> Dict[str, Any]:
        """ì˜¤ë˜ëœ íŠ¹ê°€ ìƒí’ˆ ì •ë¦¬"""
        try:
            deleted_count = self.repository.delete_old_products(days)
            return {
                "success": True,
                "deleted_count": deleted_count,
                "message": f"{days}ì¼ ì´ì „ì˜ íŠ¹ê°€ ìƒí’ˆ {deleted_count}ê°œë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤."
            }
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë˜ëœ ìƒí’ˆ ì •ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "deleted_count": 0,
                "error_message": str(e)
            }


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
special_deals_service = SpecialDealsService() 