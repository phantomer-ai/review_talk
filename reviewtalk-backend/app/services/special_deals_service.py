"""
íŠ¹ê°€ ìƒí’ˆ ì„œë¹„ìŠ¤ - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
"""
import asyncio
from typing import List, Dict, Any
from datetime import datetime

from loguru import logger

from app.models.schemas import (
    SpecialProduct, 
    SpecialProductsResponse, 
    CrawlSpecialProductsRequest,
    CrawlSpecialProductsResponse
)
from app.infrastructure.special_product_repository import special_product_repository
from app.infrastructure.crawler.special_deals_crawler import crawl_special_deals
from app.infrastructure.crawler.danawa_crawler import crawl_danawa_reviews
from app.services.ai_service import AIService


class SpecialDealsService:
    """íŠ¹ê°€ ìƒí’ˆ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.repository = special_product_repository
        self.ai_service = AIService()
    
    async def crawl_and_save_special_deals(
        self, 
        request: CrawlSpecialProductsRequest
    ) -> CrawlSpecialProductsResponse:
        """íŠ¹ê°€ ìƒí’ˆ í¬ë¡¤ë§ ë° ì €ì¥"""
        logger.info(f"ğŸš€ íŠ¹ê°€ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘ - ìµœëŒ€ {request.max_products}ê°œ")
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            self.repository.init_db()
            
            # 1. íŠ¹ê°€ ìƒí’ˆ ëª©ë¡ í¬ë¡¤ë§
            logger.info("ğŸ“¦ íŠ¹ê°€ ìƒí’ˆ ëª©ë¡ í¬ë¡¤ë§ ì¤‘...")
            special_products = await crawl_special_deals(request.max_products)
            
            if not special_products:
                return CrawlSpecialProductsResponse(
                    success=False,
                    total_products=0,
                    products_with_reviews=0,
                    total_reviews=0,
                    error_message="íŠ¹ê°€ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # 2. íŠ¹ê°€ ìƒí’ˆ ì €ì¥
            saved_count = self.repository.save_special_products(special_products)
            logger.info(f"âœ… {saved_count}ê°œì˜ íŠ¹ê°€ ìƒí’ˆ ì €ì¥ ì™„ë£Œ")
            
            # 3. ê° ìƒí’ˆë³„ ë¦¬ë·° í¬ë¡¤ë§ (ì˜µì…˜)
            products_with_reviews = 0
            total_reviews = 0
            
            if request.crawl_reviews:
                logger.info("ğŸ“ ê° ìƒí’ˆë³„ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘...")
                
                for i, product in enumerate(special_products):
                    try:
                        logger.info(f"ğŸ“– ìƒí’ˆ {i+1}/{len(special_products)}: {product.product_name}")
                        
                        # ë¦¬ë·° í¬ë¡¤ë§
                        review_result = await crawl_danawa_reviews(
                            product.product_url, 
                            request.max_reviews_per_product
                        )
                        
                        if review_result.get("success") and review_result.get("reviews"):
                            reviews = review_result["reviews"]
                            review_count = len(reviews)
                            
                            # AI ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ë¦¬ë·° ì €ì¥ (URL í¬ë¡¤ë§ê³¼ ë™ì¼í•œ ë°©ì‹)
                            try:
                                product_info = {
                                    "product_name": product.product_name,
                                    "product_image": product.image_url,
                                    "product_price": product.price,
                                    "product_brand": product.brand
                                }
                                
                                ai_result = self.ai_service.process_and_store_reviews(
                                    reviews=reviews,
                                    product_url=product.product_url,
                                    product_info=product_info
                                )
                                logger.info(f"ğŸ¤– {product.product_name} AI ì €ì¥ ê²°ê³¼: {ai_result['message']}")
                                
                                # í¬ë¡¤ë§ ìƒíƒœ ì—…ë°ì´íŠ¸
                                self.repository.update_crawl_status(
                                    product.product_id, 
                                    True, 
                                    review_count
                                )
                                
                                products_with_reviews += 1
                                total_reviews += review_count
                                
                                logger.info(f"âœ… {product.product_name}: {review_count}ê°œ ë¦¬ë·° ì €ì¥")
                                
                            except Exception as ai_error:
                                logger.error(f"âŒ {product.product_name} AI ì €ì¥ ì‹¤íŒ¨: {ai_error}")
                        else:
                            logger.warning(f"âš ï¸ {product.product_name}: ë¦¬ë·° í¬ë¡¤ë§ ì‹¤íŒ¨")
                        
                        # ê° ìƒí’ˆ ì²˜ë¦¬ í›„ ì ì‹œ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                        await asyncio.sleep(2)
                        
                    except Exception as e:
                        logger.error(f"âŒ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ ì˜¤ë¥˜ ({product.product_name}): {e}")
                        continue
            
            return CrawlSpecialProductsResponse(
                success=True,
                total_products=saved_count,
                products_with_reviews=products_with_reviews,
                total_reviews=total_reviews
            )
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ê°€ ìƒí’ˆ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
            return CrawlSpecialProductsResponse(
                success=False,
                total_products=0,
                products_with_reviews=0,
                total_reviews=0,
                error_message=str(e)
            )
    

    
    def get_special_products(self, limit: int = 50, offset: int = 0) -> SpecialProductsResponse:
        """íŠ¹ê°€ ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
        try:
            products = self.repository.get_special_products(limit, offset)
            total_count = self.repository.get_total_count()
            
            return SpecialProductsResponse(
                success=True,
                total_count=total_count,
                products=products
            )
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ê°€ ìƒí’ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return SpecialProductsResponse(
                success=False,
                total_count=0,
                products=[],
                error_message=str(e)
            )
    
    def get_special_product_by_id(self, product_id: str) -> SpecialProduct:
        """íŠ¹ì • íŠ¹ê°€ ìƒí’ˆ ì¡°íšŒ"""
        try:
            return self.repository.get_special_product_by_id(product_id)
        except Exception as e:
            logger.error(f"âŒ íŠ¹ê°€ ìƒí’ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    async def process_uncrawled_products(self, batch_size: int = 5) -> Dict[str, Any]:
        """ì•„ì§ ë¦¬ë·°ê°€ í¬ë¡¤ë§ë˜ì§€ ì•Šì€ ìƒí’ˆë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
        logger.info(f"ğŸ”„ ë¯¸í¬ë¡¤ë§ ìƒí’ˆ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
        
        try:
            # ë¯¸í¬ë¡¤ë§ ìƒí’ˆ ì¡°íšŒ
            uncrawled_products = self.repository.get_uncrawled_products(batch_size)
            
            if not uncrawled_products:
                return {
                    "success": True,
                    "processed_count": 0,
                    "message": "ì²˜ë¦¬í•  ë¯¸í¬ë¡¤ë§ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤."
                }
            
            processed_count = 0
            total_reviews = 0
            
            for product in uncrawled_products:
                try:
                    logger.info(f"ğŸ“ ë¦¬ë·° í¬ë¡¤ë§: {product.product_name}")
                    
                    # ë¦¬ë·° í¬ë¡¤ë§
                    review_result = await crawl_danawa_reviews(product.product_url, 100)
                    
                    if review_result.get("success") and review_result.get("reviews"):
                        reviews = review_result["reviews"]
                        review_count = len(reviews)
                        
                        # AI ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ë¦¬ë·° ì €ì¥ (URL í¬ë¡¤ë§ê³¼ ë™ì¼í•œ ë°©ì‹)
                        try:
                            product_info = {
                                "product_name": product.product_name,
                                "product_image": product.image_url,
                                "product_price": product.price,
                                "product_brand": product.brand
                            }
                            
                            ai_result = self.ai_service.process_and_store_reviews(
                                reviews=reviews,
                                product_url=product.product_url,
                                product_info=product_info
                            )
                            logger.info(f"ğŸ¤– {product.product_name} AI ì €ì¥ ê²°ê³¼: {ai_result['message']}")
                            
                            # í¬ë¡¤ë§ ìƒíƒœ ì—…ë°ì´íŠ¸
                            self.repository.update_crawl_status(
                                product.product_id, 
                                True, 
                                review_count
                            )
                            
                            processed_count += 1
                            total_reviews += review_count
                            
                            logger.info(f"âœ… {product.product_name}: {review_count}ê°œ ë¦¬ë·° ì²˜ë¦¬ ì™„ë£Œ")
                            
                        except Exception as ai_error:
                            logger.error(f"âŒ {product.product_name} AI ì €ì¥ ì‹¤íŒ¨: {ai_error}")
                            # ì‹¤íŒ¨í•´ë„ ìƒíƒœëŠ” ì—…ë°ì´íŠ¸ (ì¬ì‹œë„ ë°©ì§€)
                            self.repository.update_crawl_status(product.product_id, True, 0)
                    else:
                        # ì‹¤íŒ¨í•´ë„ ìƒíƒœëŠ” ì—…ë°ì´íŠ¸ (ì¬ì‹œë„ ë°©ì§€)
                        self.repository.update_crawl_status(product.product_id, True, 0)
                        logger.warning(f"âš ï¸ {product.product_name}: ë¦¬ë·° í¬ë¡¤ë§ ì‹¤íŒ¨")
                    
                    # ê° ìƒí’ˆ ì²˜ë¦¬ í›„ ëŒ€ê¸°
                    await asyncio.sleep(3)
                    
                except Exception as e:
                    logger.error(f"âŒ ìƒí’ˆ ì²˜ë¦¬ ì˜¤ë¥˜ ({product.product_name}): {e}")
                    # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.repository.update_crawl_status(product.product_id, True, 0)
                    continue
            
            return {
                "success": True,
                "processed_count": processed_count,
                "total_reviews": total_reviews,
                "message": f"{processed_count}ê°œ ìƒí’ˆì˜ ë¦¬ë·°ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¯¸í¬ë¡¤ë§ ìƒí’ˆ ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "processed_count": 0,
                "total_reviews": 0,
                "error_message": str(e)
            }
    
    def cleanup_old_products(self, days: int = 7) -> Dict[str, Any]:
        """ì˜¤ë˜ëœ íŠ¹ê°€ ìƒí’ˆ ì •ë¦¬"""
        try:
            deleted_count = self.repository.delete_old_products(days)
            return {
                "success": True,
                "deleted_count": deleted_count,
                "message": f"{days}ì¼ ì´ì „ì˜ íŠ¹ê°€ ìƒí’ˆ {deleted_count}ê°œë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤."
            }
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë˜ëœ ìƒí’ˆ ì •ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "deleted_count": 0,
                "error_message": str(e)
            }


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
special_deals_service = SpecialDealsService() 