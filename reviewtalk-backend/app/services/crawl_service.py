import asyncio
from typing import Dict, Any
from urllib.parse import urlparse
from loguru import logger

from app.infrastructure.crawler.danawa_crawler import crawl_danawa_reviews
from app.models.schemas import CrawlRequest, CrawlResponse, CrawlSpecialProductsRequest
from app.services.ai_service import AIService
from app.utils.url_utils import extract_product_id
from app.services.special_deals_service import special_deals_service


class CrawlService:
    """í¬ë¡¤ë§ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.ai_service = AIService()
    
    @staticmethod
    def validate_url(url: str) -> bool:
        """URL ìœ íš¨ì„± ê²€ì¦"""
        try:
            parsed = urlparse(str(url))
            # ë‹¤ë‚˜ì™€ ë„ë©”ì¸ ì²´í¬ (danawa.com ë˜ëŠ” danawa.page.link)
            is_danawa_domain = any([
                'danawa.com' in parsed.netloc,
                'danawa.page.link' in parsed.netloc
            ])
            return (
                parsed.scheme in ['http', 'https'] and
                is_danawa_domain
            )
        except Exception:
            return False
    
    async def crawl_product_reviews(self, request: CrawlRequest) -> CrawlResponse:
        """ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜ (íŠ¹ê°€ ìƒí’ˆ ë¦¬ë·°ë„ í•¨ê»˜ ì²˜ë¦¬)"""
        product_url = str(request.product_url)
        max_reviews = request.max_reviews
        
        # URL ìœ íš¨ì„± ê²€ì¦
        if not CrawlService.validate_url(product_url):
            return CrawlResponse(
                success=False,
                message="ìœ íš¨í•˜ì§€ ì•Šì€ ë‹¤ë‚˜ì™€ URLì…ë‹ˆë‹¤.",
                reviews_found=0,
                product_id="invalid",
                error_message="ìœ íš¨í•˜ì§€ ì•Šì€ ë‹¤ë‚˜ì™€ URLì…ë‹ˆë‹¤."
            )

        product_id = extract_product_id(product_url)

        try:
            # 1. ì…ë ¥ëœ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ (ë©”ì¸ ì‘ì—…)
            logger.info(f"ğŸ” ë©”ì¸ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘: {product_url}")
            result = await asyncio.wait_for(
                crawl_danawa_reviews(product_url, max_reviews),
                timeout=600.0
            )
            
            # í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CrawlResponse êµ¬ì¡°ë¡œ ë³€í™˜
            if result.get('success', False):
                reviews = result.get('reviews', [])
                review_count = len(reviews)
                
                crawl_response = CrawlResponse(
                    success=True,
                    message=f"ë¦¬ë·° í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ {review_count}ê°œ)",
                    reviews_found=review_count,
                    product_id=product_id,
                    product_info={
                        "product_name": result.get('product_name'),
                        "product_image": result.get('product_image'),
                        "product_price": result.get('product_price'),
                        "product_brand": result.get('product_brand')
                    }
                )
                
                # AI ì„œë¹„ìŠ¤ì— ë¦¬ë·° ì €ì¥
                if reviews:
                    try:
                        product_info = {
                            "product_name": result.get('product_name'),
                            "product_image": result.get('product_image'),
                            "product_price": result.get('product_price'),
                            "product_brand": result.get('product_brand')
                        }

                        product_id_int = int(product_id) if product_id is not None else None
                        ai_result = self.ai_service.process_and_store_reviews(
                            reviews=reviews,
                            product_id=product_id_int,
                            product_info=product_info
                        )
                        logger.info(f"ğŸ¤– ë©”ì¸ ìƒí’ˆ AI ì €ì¥ ê²°ê³¼: {ai_result['message']}")
                    except Exception as ai_error:
                        logger.warning(f"âš ï¸ ë©”ì¸ ìƒí’ˆ AI ì €ì¥ ì‹¤íŒ¨ (í¬ë¡¤ë§ì€ ì„±ê³µ): {ai_error}")
            else:
                crawl_response = CrawlResponse(
                    success=False,
                    message=result.get('error_message', 'ë¦¬ë·° í¬ë¡¤ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'),
                    reviews_found=0,
                    product_id=product_id,
                    error_message=result.get('error_message', 'ë¦¬ë·° í¬ë¡¤ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
                )

            # 2. ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŠ¹ê°€ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ íŠ¸ë¦¬ê±° (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰)
            asyncio.create_task(self._trigger_special_deals_crawling())
            
            return crawl_response
            
        except asyncio.TimeoutError:
            return CrawlResponse(
                success=False,
                message="í¬ë¡¤ë§ ì‹œê°„ ì´ˆê³¼ (600ì´ˆ)",
                reviews_found=0,
                product_id=product_id,
                error_message="í¬ë¡¤ë§ ì‹œê°„ ì´ˆê³¼ (600ì´ˆ)"
            )
        except Exception as e:
            return CrawlResponse(
                success=False,
                message=f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                reviews_found=0,
                product_id=product_id,
                error_message=f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )

    async def _trigger_special_deals_crawling(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŠ¹ê°€ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ ì‹¤í–‰"""
        try:
            logger.info("ğŸ·ï¸ ë°±ê·¸ë¼ìš´ë“œ íŠ¹ê°€ ìƒí’ˆ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘")

            # íŠ¹ê°€ ìƒí’ˆ ëª©ë¡ ì—…ë°ì´íŠ¸ (ë¦¬ë·° í¬í•¨)
            special_request = CrawlSpecialProductsRequest(
                max_products=6,  # ìµœëŒ€ 6ê°œ ìƒí’ˆ
                crawl_reviews=True,  # ë¦¬ë·°ë„ í•¨ê»˜ í¬ë¡¤ë§
                max_reviews_per_product=100  # ìƒí’ˆë‹¹ ìµœëŒ€ 100ê°œ ë¦¬ë·°
            )

            # íŠ¹ê°€ ìƒí’ˆ í¬ë¡¤ë§ ë° ë¦¬ë·° ìˆ˜ì§‘
            special_result = await special_deals_service.crawl_and_save_special_deals(special_request)

            if special_result.success:
                logger.info(f"âœ… íŠ¹ê°€ ìƒí’ˆ ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì™„ë£Œ: "
                          f"ìƒí’ˆ {special_result.total_products}ê°œ, "
                          f"ë¦¬ë·° ìˆëŠ” ìƒí’ˆ {special_result.products_with_reviews}ê°œ, "
                          f"ì´ ë¦¬ë·° {special_result.total_reviews}ê°œ")
            else:
                logger.warning(f"âš ï¸ íŠ¹ê°€ ìƒí’ˆ ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì‹¤íŒ¨: {special_result.error_message}")

        except Exception as e:
            logger.error(f"âŒ íŠ¹ê°€ ìƒí’ˆ ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")